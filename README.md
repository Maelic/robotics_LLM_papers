# Robotics Papers that use LLMs for open-world reasoning

## 2023

- **[RT-2]** RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control
[[paper](https://robotics-transformer2.github.io/assets/rt2.pdf)] [[project](https://robotics-transformer2.github.io/)]

- **[VoxPoser]** VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models
[[paper](https://arxiv.org/pdf/2307.05973.pdf)] [[project](https://voxposer.github.io/)]

## 2022

- **[SayCan]** Do As I Can, Not As I Say: Grounding Language in Robotic Affordances
[[paper](https://say-can.github.io/assets/palm_saycan.pdf)] [[project](https://say-can.github.io/)] [[code](https://github.com/google-research/google-research/tree/master/saycan)] 

- **[RT-1]** RT-1: Robotics Transformer for Real-World Control at Scale
[[paper](https://robotics-transformer1.github.io/assets/rt1.pdf)] [[project](https://robotics-transformer1.github.io/)] [[code](https://github.com/google-research/robotics_transformer)] 

